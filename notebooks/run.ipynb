{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### IMPORT YOLO Packages\n",
    "### IMPORT WANDB AND MANAGE MODEL TRAINING MONITORING ## ALSO AUTOML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOGGER ###\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging_str = \"[%(asctime)s: %(levelname)s: %(module)s: %(message)s]\"\n",
    "log_dir = \"logs\"\n",
    "log_filepath = os.path.join(log_dir,\"running_logs.log\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level= logging.INFO,\n",
    "    format= logging_str,\n",
    "\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filepath),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"license_plate_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PLAYING WITH ENV VARIABLE SO THAT WE CAN EASILY IMPORT PACKAGES OR FILES## \n",
    "from pathlib import Path\n",
    "ENV_FILE = Path.cwd().parent / \".env\"\n",
    "PROJECT_PATH = Path.cwd().parent\n",
    "CONFIGS_PATH = Path.cwd().parent / \"src\" /\"configs\"\n",
    "\n",
    "CONFIG = CONFIGS_PATH / \"config.yaml\"\n",
    "CONFIG.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-26 01:25:27,200: INFO: 667455139: yaml file: /home/vikram/Documents/portfolio/license_plate_classification/src/configs/config.yaml loaded successfully]\n"
     ]
    }
   ],
   "source": [
    "### LOAD YAML PARAMETERS\n",
    "import yaml\n",
    "\n",
    "\n",
    "with open(CONFIG) as file:\n",
    "    data = yaml.safe_load(file)\n",
    "    logger.info(f\"yaml file: {CONFIG} loaded successfully\")\n",
    "\n",
    "folder_path= \"data/License_coco\"\n",
    "data_path = PROJECT_PATH / folder_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vikram/Documents/portfolio/license_plate_classification/data/License_coco/README.roboflow.txt\n",
      "/home/vikram/Documents/portfolio/license_plate_classification/data/License_coco/train\n",
      "/home/vikram/Documents/portfolio/license_plate_classification/data/License_coco/test\n",
      "/home/vikram/Documents/portfolio/license_plate_classification/data/License_coco/valid\n",
      "/home/vikram/Documents/portfolio/license_plate_classification/data/License_coco/README.dataset.txt\n"
     ]
    }
   ],
   "source": [
    "for path in data_path.iterdir():\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What kind of a data loader for Yolo which requires to create folders?\n",
    "## Maybe create a class that will create the folders, add augmentations to training images \n",
    "# and return back the path of folders.\n",
    "# How to modify bounding boxes training data for augmentations?\n",
    "# Also need to think of bounding boxes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/vikram/Documents/portfolio/license_plate_classification/data/License_coco')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_folder = Path(PROJECT_PATH/'data'/'License_coco')\n",
    "raw_data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport albumentations as A\\nimport cv2\\n\\ntransform = A.Compose([\\n    A.RandomCrop(width=450, height=450),\\n    A.HorizontalFlip(p=0.5),\\n    A.RandomBrightnessContrast(p=0.2),\\n], bbox_params=A.BboxParams(format='coco'))\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOT REQUIRED\n",
    "'''\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.RandomCrop(width=450, height=450),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "], bbox_params=A.BboxParams(format='coco'))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD TO UTILS and add typing\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def coco_image_annotations(anno_file):\n",
    "    if not Path.exists(anno_file):\n",
    "        raise FileNotFoundError(anno_file)\n",
    "    \n",
    "    ## Load json and convert to file in yolo format\n",
    "\n",
    "    with open(anno_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    images = {\"{:g}\".format(x[\"id\"]): x for x in data[\"images\"]}\n",
    "    img_to_anno=defaultdict(list)\n",
    "    for anno in data['annotations']:\n",
    "        img_to_anno[f\"{anno['image_id']}\"].append(anno)\n",
    "\n",
    "    return images, img_to_anno \n",
    "\n",
    "\n",
    "def coco_to_yolo_bbox(bbox:List, img_width, img_height)->List:\n",
    "    \"\"\"\n",
    "    Return bounding boxes in yolo format given List of bbox in coco format\n",
    "    \"\"\"\n",
    "   \n",
    "    # The COCO box format is [top left x, top left y, width, height]\n",
    "    box = np.array(bbox, dtype=np.float64)\n",
    "    if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "        return None\n",
    "    \n",
    "    box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "    box[[0, 2]] /= img_width # normalize x\n",
    "    box[[1, 3]] /= img_height  # normalize y\n",
    "\n",
    "    return box.tolist()\n",
    "\n",
    "## ADD \n",
    "def augment_image(img, bbox:List, augment_fn=None, bounding_box_type=None):\n",
    "    \"\"\"\n",
    "    Return a tuple of image and bounding boxes in specified formataugment_image_bounding_box\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4046875, 0.840625, 0.503125, 0.24375]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = [98,345,322,117]\n",
    "w = 640\n",
    "h = 480\n",
    "coco_to_yolo_bbox(test_list, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = raw_data_folder/'test'\n",
    "labels_folder = raw_data_folder/'test/labels'\n",
    "train_anno_file = train_folder/'_annotations.coco.json'\n",
    "\n",
    "images, img_to_anno = coco_image_annotations(train_anno_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 200,\n",
       "  'license': 1,\n",
       "  'file_name': 'CarLongPlateGen3793_jpg.rf.318f593c294007d7ceadcd771018e075.jpg',\n",
       "  'height': 303,\n",
       "  'width': 472,\n",
       "  'date_captured': '2023-01-30T07:40:17+00:00'},\n",
       " [251, 219, 79, 49])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['200'], img_to_anno['200'][0]['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for img_id, anns in tqdm(img_to_anno.items()):\n",
    "    img = images[img_id]\n",
    "    h, w, f = img[\"height\"], img[\"width\"], img[\"file_name\"]\n",
    "\n",
    "    bboxes = []\n",
    "    bboxes_augmented = []\n",
    "    # AUGMENT THE IMAGE and get augmented bounded boxes\n",
    "    \n",
    "    for ann in anns: \n",
    "        bboxes.append(coco_to_yolo_bbox(ann['bbox'],w,h))\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Can look for a better and easy way and make it a function of writing yolo annotations\n",
    "    with open((labels_folder / f).with_suffix(\".txt\"), \"a\") as file:\n",
    "        for i in range(len(bboxes)):\n",
    "            line = (0,*(bboxes[i]),)  # box           \n",
    "            file.write((\"%g \" * len(line)).rstrip() % line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bounding_box(image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "    \n",
    "    plotted_image = ImageDraw.Draw(image)\n",
    "\n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
    "    \n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "    \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)))\n",
    "        \n",
    "        plotted_image.text((x0, y0 - 10), \"License Plate\")\n",
    "    \n",
    "    plt.imshow(np.array(image))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIG VARIABLES\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.23 ðŸš€ Python-3.10.15 torch-2.5.0 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 3799MiB)\n",
      "Setup complete âœ… (12 CPUs, 30.7 GB RAM, 309.9/1823.8 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the model and running validation files\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "results = model.train(data=CONFIG, epochs=150, imgsz=420, plots=True, name='size_420_AdamW', save_period=10, optimizer='AdamW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "0.20.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "print(torch.__version__) \n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(PROJECT_PATH/\"notebooks/runs/detect/run2/weights/best.pt\")\n",
    "results = model.tune(data=CONFIG, epochs=30, imgsz=640,plots=True, iterations=300, optimizer=\"AdamW\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inference\n",
    "from ultralytics import YOLO\n",
    "\n",
    "inf_model_path=PROJECT_PATH/\"notebooks/runs/detect/size_420/weights/best.pt\"\n",
    "inf_model = YOLO(inf_model_path)\n",
    "inp_source = raw_data_folder/'test/images'\n",
    "#source2 = raw_data_folder/'test/images/00a7d31c6cc6b7f3_jpg.rf.641695200cda83be76f64c5402215f27.jpg'\n",
    "\n",
    "def inference(source, model=\"yolo11n.pt\", save_path=None, show=None ):\n",
    "    \"\"\"\n",
    "    Source can be directory, image file, np.array containing image\n",
    "    \"\"\"\n",
    "    if source: ## Depending on type , Have to change inference\n",
    "        out = inf_model(inp_source, stream=True) ## FOR DIRECTORY\n",
    "    \n",
    "\n",
    "    # Run inference on the source\n",
    "    files = Path(inp_source).glob('*')\n",
    "    for file in files:\n",
    "        out2 = inf_model(file)\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# Visualize the results\n",
    "for i, r in enumerate(out2):\n",
    "    # Plot results image\n",
    "    im_bgr = r.plot()  # BGR-order numpy array\n",
    "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "    # Show results to screen (in supported environments)\n",
    "    r.show()\n",
    "    # Save results to disk\n",
    "    r.save(filename=f\"out2.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Abstraction of the model into a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PIPELINING THE CODE\n",
    "## ADD APP for inference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
